# ğŸ¤– BeCoin Autonomous System - Setup Guide

## Ãœbersicht

Das BeCoin System kann in 3 Modi betrieben werden:

1. **Manual Mode** - Manuelle AusfÃ¼hrung von PlÃ¤nen mit dem Orchestrator
2. **Continuous Simulation** - Kontinuierliche Wirtschaftssimulation mit Live-Updates
3. **Background Service** - Dauerhafter Betrieb als Systemdienst

## âš¡ Quick Start

### Option 1: Manuelle AusfÃ¼hrung (One-Shot)

```bash
# 1. Setup ausfÃ¼hren (einmalig)
./autonomous_agents/setup_autonomous_agents.sh

# 2. Plan ausfÃ¼hren
python3 autonomous_agents/orchestrator.py docs/plans/example-plan.md
```

### Option 2: Kontinuierliche Simulation

```bash
# System starten (lÃ¤uft im Vordergrund)
./autonomous_startup.sh
```

**Was passiert:**
- âœ… Ollama wird geprÃ¼ft und ggf. gestartet
- âœ… AI-Model wird geprÃ¼ft und ggf. heruntergeladen
- âœ… Wirtschaftsdaten werden generiert
- âœ… Simulation lÃ¤uft in 5-Sekunden-Zyklen (1 simulierte Stunde pro Zyklus)
- âœ… Dashboard-Daten werden alle 5 Sekunden aktualisiert
- âœ… Live-Updates auf https://becoin-ecosim-llm.fly.dev/

**Beenden:** `Ctrl+C`

### Option 3: Als Hintergrunddienst (Empfohlen)

```bash
# Service installieren und starten
sudo ./install_service.sh
```

**Service-Befehle:**

```bash
# Status prÃ¼fen
sudo systemctl status becoin-autonomous

# Logs anzeigen (live)
sudo journalctl -u becoin-autonomous -f

# Service stoppen
sudo systemctl stop becoin-autonomous

# Service starten
sudo systemctl start becoin-autonomous

# Service neustarten
sudo systemctl restart becoin-autonomous

# Service deaktivieren (bei Boot nicht mehr starten)
sudo systemctl disable becoin-autonomous
```

## ğŸ—ï¸ Systemarchitektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Autonomes System                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚   Ollama     â”‚â—„â”€â”€â”€â”€â–ºâ”‚ Qwen2.5-7B   â”‚               â”‚
â”‚  â”‚  (LLM Server)â”‚      â”‚   (Model)    â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚         â”‚                                               â”‚
â”‚         â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚      BeCoin Economy Engine           â”‚              â”‚
â”‚  â”‚  â€¢ Treasury Management               â”‚              â”‚
â”‚  â”‚  â€¢ Agent Orchestration               â”‚              â”‚
â”‚  â”‚  â€¢ Project Lifecycle                 â”‚              â”‚
â”‚  â”‚  â€¢ Burn Rate Simulation              â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚         â”‚                                               â”‚
â”‚         â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚      Dashboard Exporter              â”‚              â”‚
â”‚  â”‚  â€¢ treasury.json                     â”‚              â”‚
â”‚  â”‚  â€¢ agent-roster.json                 â”‚              â”‚
â”‚  â”‚  â€¢ projects.json                     â”‚              â”‚
â”‚  â”‚  â€¢ impact-ledger.json                â”‚              â”‚
â”‚  â”‚  â€¢ orchestrator-status.json          â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚         â”‚                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Fly.io Deploy   â”‚
  â”‚   Dashboard UI    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Simulation-Zyklus

```
Cycle 1 (t=0h)    â†’ Balance: $8500, Projects: 2 active
   â†“ (5 sec / 1h simulated)
Cycle 2 (t=1h)    â†’ Burn $120, Progress +5%, Balance: $8380
   â†“
Cycle 3 (t=2h)    â†’ Burn $120, Progress +10%, Balance: $8260
   â†“
... kontinuierlich ...
```

**Simulation-Events:**
- 30% Chance pro Zyklus: Projekt-Fortschritt (+5-15%)
- Projekte bei 100% â†’ Status: completed
- Treasury Burn: -$120/h (konfigurierbar)
- JSON-Export: Alle 5 Sekunden
- Dashboard-Update: Real-time via Live-Reload

## ğŸ”§ Konfiguration

### Economy Parameter

Editiere `autonomous_startup.sh` (Zeile 105+):

```python
# Treasury
treasury = Treasury(start_capital=10000, balance=8500)  # Anpassen

# Burn Rate
baseline_hourly_burn=120.0  # StÃ¼ndliche Kosten

# Simulation Speed
time.sleep(5)  # Sekunden pro Zyklus (5 = 1 simulierte Stunde)
```

### Ollama Model

Andere Modelle verwenden:

```bash
# Alternatives Model herunterladen
ollama pull llama3.1:8b

# In autonomous_startup.sh Ã¤ndern (Zeile 30)
if ollama list | grep -q "llama3.1:8b"; then
```

## ğŸ“ Wichtige Dateien

```
.
â”œâ”€â”€ autonomous_startup.sh          # Haupt-Startup-Script
â”œâ”€â”€ install_service.sh             # Service-Installation
â”œâ”€â”€ becoin-autonomous.service      # systemd Service-Definition
â”œâ”€â”€ autonomous_agents/
â”‚   â”œâ”€â”€ orchestrator.py            # Plan-basierte AusfÃ¼hrung
â”‚   â”œâ”€â”€ monitor.py                 # Log-Monitoring
â”‚   â”œâ”€â”€ logs/                      # Execution Logs
â”‚   â””â”€â”€ personalities/             # 51 Agenten-PersÃ¶nlichkeiten
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ becoin-economy/            # Live Dashboard-Daten
â”‚   â”‚   â”œâ”€â”€ treasury.json
â”‚   â”‚   â”œâ”€â”€ agent-roster.json
â”‚   â”‚   â”œâ”€â”€ projects.json
â”‚   â”‚   â”œâ”€â”€ impact-ledger.json
â”‚   â”‚   â””â”€â”€ orchestrator-status.json
â”‚   â””â”€â”€ office-ui.html             # Frontend
â””â”€â”€ docs/plans/                    # Implementation Plans
```

## ğŸ” Monitoring

### Live Dashboard

https://becoin-ecosim-llm.fly.dev/

### Logs Anzeigen

```bash
# Service Logs (live)
sudo journalctl -u becoin-autonomous -f

# Letzte 100 Zeilen
sudo journalctl -u becoin-autonomous -n 100

# Logs seit gestern
sudo journalctl -u becoin-autonomous --since yesterday

# Nur Fehler
sudo journalctl -u becoin-autonomous -p err
```

### Status PrÃ¼fen

```bash
# Ollama Status
curl http://localhost:11434/api/tags

# Models auflisten
ollama list

# Economy Status (API)
curl http://localhost:3000/api/status

# Dashboard JSON
ls -lh dashboard/becoin-economy/
```

## ğŸ› Troubleshooting

### Ollama startet nicht

```bash
# Manuell starten
ollama serve

# Oder als user service
systemctl --user start ollama
```

### Model nicht gefunden

```bash
# Model neu herunterladen
ollama pull qwen2.5-coder:7b

# VerfÃ¼gbare Models prÃ¼fen
ollama list
```

### Service startet nicht

```bash
# Logs prÃ¼fen
sudo journalctl -u becoin-autonomous -n 50

# Manuell testen
./autonomous_startup.sh

# Permissions prÃ¼fen
ls -la autonomous_startup.sh
# Sollte -rwxr-xr-x sein
```

### Dashboard zeigt keine Updates

```bash
# JSON-Dateien prÃ¼fen
ls -lht dashboard/becoin-economy/

# Letzte Ã„nderung sollte < 10 Sekunden sein
stat dashboard/becoin-economy/treasury.json

# File-Content prÃ¼fen
cat dashboard/becoin-economy/treasury.json | jq .balance
```

## ğŸš€ Deployment

Das System lÃ¤uft lokal und exportiert Daten fÃ¼r das Fly.io Dashboard.

**Workflow:**
1. Lokale Simulation lÃ¤uft: `./autonomous_startup.sh`
2. Generiert JSON-Daten: `dashboard/becoin-economy/*.json`
3. Fly.io Dashboard liest Daten: Via Static Files Mount
4. Live-Updates: JSON wird alle 5 Sekunden aktualisiert

**FÃ¼r echte Live-Synchronisation:**

```bash
# Dashboard neu deployen mit aktuellen Daten
fly deploy

# Oder: Rsync/SCP Setup fÃ¼r automatisches Upload
# (Advanced - benÃ¶tigt zusÃ¤tzliche Konfiguration)
```

## ğŸ’¡ Tipps

1. **Performance**: Auf einem Server mit GPU lÃ¤uft Ollama schneller
2. **Memory**: Qwen2.5-Coder 7B benÃ¶tigt ~8GB RAM
3. **Disk**: ~5GB fÃ¼r Model + Dependencies
4. **Logs**: Logs rotieren automatisch (systemd journal)
5. **Backup**: Dashboard-Daten sind reproduzierbar (keine Backups nÃ¶tig)

## ğŸ“š Weitere Dokumentation

- [Autonomous Agents README](autonomous_agents/README.md)
- [Deployment Guide](DEPLOYMENT.md)
- [Main README](README.md)
- [Claude.md](CLAUDE.md)

## ğŸ¯ Use Cases

### 1. Entwicklung & Testing
```bash
# Vordergrund-Modus mit Live-Output
./autonomous_startup.sh
```

### 2. Demo & PrÃ¤sentation
```bash
# Service-Modus (lÃ¤uft im Hintergrund)
sudo ./install_service.sh
# Dashboard: https://becoin-ecosim-llm.fly.dev/
```

### 3. Production (24/7)
```bash
# Service installieren
sudo ./install_service.sh

# Monitoring einrichten
sudo journalctl -u becoin-autonomous -f | tee -a monitoring.log
```

---

**Built with â¤ï¸ for autonomous AI development**
